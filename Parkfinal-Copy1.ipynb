{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing RandomOverSampler from sklearn's impute module\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Other necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d678a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.dpi\":300, 'savefig.dpi':300})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "pd.set_option('display.max_columns',29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data from CSV file to pandas dataframe\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75735e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing first five rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing last five rows of the data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773eb8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns in our dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85956037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting more information of our dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a306dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e35ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting some statistical information of our data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa8bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of our target variable i.e. \"status\" column/feature\n",
    "df[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "explode=(0.08,0)\n",
    "\n",
    "df['status'].value_counts().plot.pie(autopct='%1.2f%%',figsize=(3,3),explode=explode,colors=['#99ff99','#ff6666'])\n",
    "plt.title(\"Pie plot of distribution of status column\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e94998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"status\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ec501",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.drop(\"name\", axis=1), hue=\"status\", diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=0.25)\n",
    "cmap = sns.diverging_palette(260, 10, as_cmap=True)\n",
    "sns.heatmap(df.drop([\"name\", \"status\"], axis=1).corr(\"spearman\"), vmax=1.2, annot=True, square='square', cmap=cmap, fmt = '.0%', linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520cd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the font scale for the plot\n",
    "sns.set(font_scale=0.25)\n",
    "\n",
    "# Create a correlation matrix using spearman method\n",
    "corr_matrix = df.drop([\"name\", \"status\"], axis=1).corr(method=\"spearman\")\n",
    "\n",
    "# Create a diverging color palette for the heatmap\n",
    "cmap = sns.diverging_palette(260, 10, as_cmap=True)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10, 8))  # Set the size of the plot\n",
    "sns.heatmap(corr_matrix, vmax=1.2, annot=True, square=True, cmap=cmap, fmt=\".0%\", linewidths=2)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91bd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.drop([\"name\", \"status\"], axis=1).corr()\n",
    "\n",
    "# Find highly correlated features\n",
    "corr_threshold = 0.85\n",
    "high_corr_features = set()  # Create a set to store correlated feature pairs\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > corr_threshold:\n",
    "            colname_i = corr_matrix.columns[i]\n",
    "            colname_j = corr_matrix.columns[j]\n",
    "            high_corr_features.add(colname_i)\n",
    "            high_corr_features.add(colname_j)\n",
    "\n",
    "# Convert the set to a list\n",
    "high_corr_features_list = list(high_corr_features)\n",
    "\n",
    "# Print the highly correlated features\n",
    "print(\"Highly correlated features:\", high_corr_features_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anova = df.drop([\"name\"], axis=1)\n",
    "grps = pd.unique(df_anova.status.values)\n",
    "\n",
    "coldrop = []\n",
    "\n",
    "for i in range(len(df_anova.columns)-1):\n",
    "    \n",
    "    d_data = {grp:df_anova[df_anova.columns[i]][df_anova.status == grp] for grp in grps}\n",
    "\n",
    "    F, p = stats.f_oneway(d_data[0], d_data[1])\n",
    "    print(\"P_Value of {} and status\".format(df_anova.columns[i]), p)\n",
    "\n",
    "    if p < 0.05:\n",
    "        print(\"There is relation between {} and status \\n\".format(df_anova.columns[i]))\n",
    "    else:\n",
    "        print(\"There is no relation between {} and status \\n\".format(df_anova.columns[i]))\n",
    "        coldrop.append(df_anova.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"name\", axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80799929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Your DataFrame 'df' and other code here\n",
    "\n",
    "var_thres = VarianceThreshold(threshold=0)\n",
    "var_thres.fit(df.drop(\"name\", axis=1))\n",
    "\n",
    "var_support = var_thres.get_support()\n",
    "\n",
    "selected_columns = df.drop(\"name\", axis=1).columns[var_support]\n",
    "print(\"Selected columns after variance threshold:\", selected_columns)\n",
    "\n",
    "constant_columns = [column for column in df.drop(\"name\", axis=1).columns if column not in selected_columns]\n",
    "print(\"Constant columns:\", constant_columns)\n",
    "print(\"Number of constant columns:\", len(constant_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200567dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you calculated the correlated features earlier in your code\n",
    "corr_features = ['feature1', 'feature2', ...]  # List of correlated features\n",
    "\n",
    "# Assuming you have defined the coldrop list as well\n",
    "coldrop = ['feature3', 'feature4', ...]  # List of columns to drop\n",
    "\n",
    "# Combining correlated features and columns to drop\n",
    "list_drop = corr_features + coldrop\n",
    "list_drop.append(\"name\")\n",
    "\n",
    "# Print the final list of columns to drop\n",
    "print(\"Columns to drop:\", list_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d127f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the current column names in the DataFrame\n",
    "print(\"Current column names:\", df.columns)\n",
    "\n",
    "# Verify the column names you intend to drop\n",
    "print(\"Columns to drop:\", list_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51565685",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"status\"], axis=1)\n",
    "y = df[\"status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f792c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming 'X' is your DataFrame containing both numerical and non-numerical columns\n",
    "\n",
    "# Select only the numerical columns from the DataFrame\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Filter the DataFrame to keep only the numerical columns\n",
    "X_numeric = X[numerical_columns]\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the StandardScaler to the numerical features\n",
    "scaled_features = scaler.fit_transform(X_numeric)\n",
    "\n",
    "# Create a DataFrame with the scaled features\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=numerical_columns)\n",
    "\n",
    "# Now 'scaled_df' contains your scaled numerical features\n",
    "print(scaled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f502c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with your features and a 'y' array for labels\n",
    "# And assuming you have performed the necessary preprocessing including scaling\n",
    "\n",
    "# Selecting the features and labels\n",
    "X = df.drop([\"name\", \"status\"], axis=1)\n",
    "y = df[\"status\"]\n",
    "\n",
    "# Assuming you have performed feature scaling on 'X' using the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "feature = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Now you can use X_train and other variables as intended\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feda504",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa23e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e722daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_train[y_train==1]), len(y_train[y_train==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70253f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f88af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_indices = np.where(y_train == 0)[0]\n",
    "class_1_indices = np.where(y_train == 1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55054d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_class_size = min(len(class_0_indices), len(class_1_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_grid_search(X, y):\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    # Create a dictionary of all values we want to test\n",
    "    solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    penalty = ['l2']\n",
    "    c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "    \n",
    "    # define grid search\n",
    "    param_grid = dict(solver=solvers, penalty=penalty, C=c_values)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    \n",
    "    return grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdb6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid_search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5964746",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.01, penalty='l2', solver='liblinear')\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_lr))\n",
    "\n",
    "lr_score = lr.score(X_train,y_train)\n",
    "print(lr_score)\n",
    "\n",
    "lr_score = lr.score(X_test,y_test)\n",
    "print(lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tacc = lr.score(X_test,y_test)\n",
    "lr_train_acc = lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred_lr, labels=[1,0])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n",
    "                         columns = [i for i in [\"Predict 1\", \"Predict 0\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = lr.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "fpr \n",
    "tpr\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "auc\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ca5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_auc = auc\n",
    "lr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab212d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree_grid_search(X, y):\n",
    "    #create a dictionary of all values we want to test\n",
    "    param_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(2, 15)}\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    \n",
    "    # decision tree model\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    \n",
    "    #use gridsearch to test all values\n",
    "    dtree_gscv = GridSearchCV(dtree, param_grid, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "    #fit model to data\n",
    "    dtree_gscv.fit(X, y)\n",
    "    \n",
    "    return dtree_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f71ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dTree = DecisionTreeClassifier(criterion = 'entropy', max_depth = 2)\n",
    "dTree.fit(X_train, y_train)\n",
    "\n",
    "print(dTree.score(X_train,y_train))\n",
    "print(dTree.score(X_test,y_test))\n",
    "\n",
    "y_pred_dtree = dTree.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_dtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489523a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tacc = dTree.score(X_test,y_test)\n",
    "dt_train_acc = dTree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b39667",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred_dtree, labels=[1,0])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n",
    "                         columns = [i for i in [\"Predict 1\", \"Predict 0\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = dTree.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "fpr \n",
    "tpr\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "auc\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_auc = auc\n",
    "dt_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91680ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_grid_search(X, y):\n",
    "    #create a dictionary of all values we want to test\n",
    "    param_grid = {'n_estimators':[10, 50, 100, 500], 'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    \n",
    "    # AdaBoost model\n",
    "    ada = AdaBoostClassifier()\n",
    "    \n",
    "    # Use gridsearch to test all values\n",
    "    ada_gscv = GridSearchCV(ada, param_grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "    #fit model to data\n",
    "    grid_result = ada_gscv.fit(X, y)\n",
    "    \n",
    "    return ada_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95031932",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_grid_search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "abcl = AdaBoostClassifier(n_estimators=15, learning_rate = 0.01)\n",
    "abcl = abcl.fit(X_train, y_train)\n",
    "\n",
    "y_pred_abcl = abcl.predict(X_test)\n",
    "\n",
    "print(abcl.score(X_train, y_train))\n",
    "print(abcl.score(X_test,y_test))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_abcl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_train_acc = abcl.score(X_train, y_train)\n",
    "ada_tacc = abcl.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred_abcl, labels=[1,0])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n",
    "                         columns = [i for i in [\"Predict 1\", \"Predict 0\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = abcl.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "fpr \n",
    "tpr\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "auc\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ff2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_auc = auc\n",
    "ada_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
